{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"tamil-utils","text":"<p>Small, production-ready Tamil-first text layer.</p> <ul> <li>Normalization &amp; graphemes</li> <li>Tamil-aware tokens</li> <li>Stopwords preset, sentence splitter, numerals</li> <li>Syllables (approx), Tamil collation (ISO-15919 key)</li> <li>v0.1 adds: script detection, ISO-15919 transliteration</li> <li>v0.3 (alpha) adds: JSONL preprocessor, spaCy tokenizer hook (optional), Hugging Face Datasets export (optional)</li> </ul>"},{"location":"#install","title":"Install","text":"<pre><code>pip install tamil-utils\n\n# optional extras\npip install \"tamil-utils[spacy]\"   # spaCy tokenizer hook\npip install datasets               # Hugging Face helper\n</code></pre>"},{"location":"#cli-quickstart","title":"CLI quickstart","text":"<pre><code># sentence split\npython -m tamil_utils.cli sents \"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0bb5\u0bbe\u0b95\u0bcd\u0b95\u0bbf\u0baf\u0bae\u0bcd. \u0b87\u0ba4\u0bc1 \u0b87\u0bb0\u0ba3\u0bcd\u0b9f\u0bbe\u0bae\u0bcd? \u0b9a\u0bb0\u0bbf!\"\n\n# Tamil \u2194 ASCII numerals\npython -m tamil_utils.cli to-arabic \"\u0be8\u0be6\u0be8\u0beb\"   # -&gt; 2025\npython -m tamil_utils.cli to-tamil \"123\"     # -&gt; \u0be7\u0be8\u0be9\n\n# word/n-gram counts\npython -m tamil_utils.cli freq -n 2 --top 5 \"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP \u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP\"\n\n# JSONL preprocessor (one record per line)\npython -m tamil_utils.cli preprocess --numerals ar --rmstop &lt; input.txt &gt; out.jsonl\n</code></pre>"},{"location":"#windows-note","title":"Windows note","text":"<p>When piping Tamil text in PowerShell, prefer UTF-8 files or run with <code>python -X utf8</code>. See Preprocess page for examples.</p>"},{"location":"#links","title":"Links","text":"<ul> <li>Usage \u2013 examples of the core API &amp; CLI \u2192 <code>usage.md</code></li> <li>API \u2013 functions and signatures \u2192 <code>api.md</code></li> <li>Recipes \u2013 common tasks for apps &amp; data \u2192 <code>recipes.md</code></li> <li>Collation \u2013 how <code>sort_tamil</code> orders words \u2192 <code>collation.md</code></li> <li>Preprocess \u2013 JSONL pipeline for RAG/ML \u2192 <code>preprocess.md</code></li> <li>spaCy \u2013 optional tokenizer hook \u2192 <code>spacy.md</code></li> <li>Hugging Face \u2013 optional dataset helper \u2192 <code>hf.md</code></li> </ul>"},{"location":"api/","title":"API","text":""},{"location":"api/#core-api","title":"Core API","text":"<pre><code>from tamil_utils import (\n    normalize, tokens, remove_stopwords, graphemes, sents,\n    to_arabic_numerals, to_tamil_numerals, syllables, sort_tamil, word_counts\n)\n\ns = \"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 \ud83d\udc69\ud83c\udffd\u200d\ud83d\udcbb \u0be8\u0be6\u0be8\u0beb\"\n\nprint(tokens(s))                                # ['\u0b87\u0ba4\u0bc1','\u0b92\u0bb0\u0bc1','\u0b9a\u0bcb\u0ba4\u0ba9\u0bc8','\ud83d\udc69\ud83c\udffd\u200d\ud83d\udcbb','\u0be8\u0be6\u0be8\u0beb']\nprint(remove_stopwords(tokens(s), preset=\"ta\")) # ['\u0b9a\u0bcb\u0ba4\u0ba9\u0bc8','\ud83d\udc69\ud83c\udffd\u200d\ud83d\udcbb','\u0be8\u0be6\u0be8\u0beb']\nprint(graphemes(\"\ud83d\udc69\ud83c\udffd\u200d\ud83d\udcbb\"))                       # ['\ud83d\udc69\ud83c\udffd\u200d\ud83d\udcbb']\nprint(sents(\"\u0b87\u0ba4\u0bc1 \u0b92\u0ba9\u0bcd\u0bb1\u0bc1. \u0b87\u0ba4\u0bc1 \u0b87\u0bb0\u0ba3\u0bcd\u0b9f\u0bc1? \u0b9a\u0bb0\u0bbf!\"))      # ['\u0b87\u0ba4\u0bc1 \u0b92\u0ba9\u0bcd\u0bb1\u0bc1.', '\u0b87\u0ba4\u0bc1 \u0b87\u0bb0\u0ba3\u0bcd\u0b9f\u0bc1?', '\u0b9a\u0bb0\u0bbf!']\nprint(to_arabic_numerals(\"\u0be8\u0be6\u0be8\u0beb\"))                 # \"2025\"\nprint(to_tamil_numerals(\"123\"))                  # \"\u0be7\u0be8\u0be9\"\nprint(syllables(\"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd\"))                         # approx syllables\nprint(sort_tamil([\"\u0b87\u0bb2\u0b99\u0bcd\u0b95\u0bc8\",\"\u0b86\u0ba4\u0bbf\",\"\u0b85\u0b9f\u0bbf\"]))         # ['\u0b85\u0b9f\u0bbf','\u0b86\u0ba4\u0bbf','\u0b87\u0bb2\u0b99\u0bcd\u0b95\u0bc8']\n</code></pre>"},{"location":"api/#useful-clis","title":"Useful CLIs","text":"<pre><code># n-gram counts (unigram/bigram/trigram)\npython -m tamil_utils.cli freq -n 2 --top 5 \"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP \u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP\"\n\n# Tamil collation via ISO-15919 key\npython -m tamil_utils.cli sort \"\u0b87\u0bb2\u0b99\u0bcd\u0b95\u0bc8\" \"\u0b86\u0ba4\u0bbf\" \"\u0b85\u0b9f\u0bbf\"\n</code></pre>"},{"location":"api/#preprocess-jsonl","title":"Preprocess (JSONL)","text":"<pre><code>python -m tamil_utils.cli preprocess --numerals ar --rmstop &lt; input.txt &gt; out.jsonl\n</code></pre>"},{"location":"api/#windows-powershell","title":"Windows PowerShell","text":"<p>Use UTF-8 when piping:</p> <pre><code>Set-Content in.txt -Value '\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 \u0be8\u0be6\u0be8\u0beb' -Encoding UTF8\nGet-Content -Raw -Encoding UTF8 .\\in.txt | python -X utf8 -m tamil_utils.cli preprocess --numerals ar --rmstop\n</code></pre>"},{"location":"api/#optional-integrations","title":"Optional integrations","text":""},{"location":"api/#spacy-tokenizer-hook","title":"spaCy tokenizer hook","text":"<pre><code>import spacy\nfrom tamil_utils.spacy_hook import install_tamil_tokenizer\n\nnlp = spacy.blank(\"xx\")\ninstall_tamil_tokenizer(nlp)\n[t.text for t in nlp(\"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 2025\")]  # ['\u0b87\u0ba4\u0bc1','\u0b92\u0bb0\u0bc1','\u0b9a\u0bcb\u0ba4\u0ba9\u0bc8','2025']\n</code></pre>"},{"location":"api/#hugging-face-datasets","title":"Hugging Face Datasets","text":"<pre><code>from tamil_utils.hf_export import to_hf_dataset  # pip install datasets\n\nrecords = [{\"text\": \"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 2025\",\n            \"tokens\": [\"\u0b87\u0ba4\u0bc1\",\"\u0b92\u0bb0\u0bc1\",\"\u0b9a\u0bcb\u0ba4\u0ba9\u0bc8\",\"2025\"]}]\nds = to_hf_dataset(records)\nprint(ds)\n</code></pre>"},{"location":"collation/","title":"Collation (Sorting) for Tamil","text":"<p><code>tamil-utils</code> provides a lightweight collation via <code>sort_tamil()</code>. It builds a stable sort key from ISO-15919 transliteration so words sort roughly as native Tamil order:</p> <p>a &lt; \u0101 &lt; i &lt; \u012b &lt; u &lt; \u016b &lt; e &lt; \u0113 &lt; ai &lt; o &lt; \u014d &lt; au</p> <p>This is deterministic and dependency-free, suitable for most app and data tasks. It is not a full Tamil Collation Algorithm (TCA) and does not depend on ICU.</p>"},{"location":"collation/#quick-usage","title":"Quick usage","text":"<pre><code>from tamil_utils import sort_tamil\n\nwords = [\"\u0b87\u0bb2\u0b99\u0bcd\u0b95\u0bc8\", \"\u0b86\u0ba4\u0bbf\", \"\u0b85\u0b9f\u0bbf\"]\nprint(sort_tamil(words))   # ['\u0b85\u0b9f\u0bbf', '\u0b86\u0ba4\u0bbf', '\u0b87\u0bb2\u0b99\u0bcd\u0b95\u0bc8']\n\nYes. That section **is part of `docs/collation.md`** right after \u201cQuick usage\u201d.\n\nHere\u2019s the exact block to paste (properly fenced):\n\n````markdown\n## When you need strict, locale-aware collation\n\nIf your product requires exact linguistic collation for Tamil (e.g., official indexes, libraries), use **ICU** where available and fall back to `sort_tamil()`.\n\n### Python (PyICU) with fallback\n\n```python\ndef sort_tamil_strict(words):\n    try:\n        from icu import Collator, Locale\n        coll = Collator.createInstance(Locale(\"ta_IN\"))\n        return sorted(words, key=coll.getSortKey)\n    except Exception:\n        from tamil_utils import sort_tamil\n        return sort_tamil(words)\n\nwords = [\"\u0b87\u0bb2\u0b99\u0bcd\u0b95\u0bc8\", \"\u0b86\u0ba4\u0bbf\", \"\u0b85\u0b9f\u0bbf\"]\nprint(sort_tamil_strict(words))\n````\n\n&gt; Install: `pip install PyICU` (platform-specific wheels may apply).\n&gt; Keep `tamil-utils` default lightweight; add ICU only if your deployment needs it.\n\n</code></pre>"},{"location":"corpus/","title":"Corpus Utilities","text":"<p>Utilities to tidy large Tamil corpora before training / RAG.</p>"},{"location":"corpus/#1-punctuation-normalization","title":"1) Punctuation normalization","text":"<pre><code>from tamil_utils.corpus import normalize_punct\n\ns = ' \u201c\u0b87\u0ba4\u0bc1\u201d  \u0b92\u0bb0\u0bc1  \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 \u2026  \u0b9a\u0bb0\u0bbf  !  \u0b87\u0ba4\u0bc1  \u0b87\u0bb0\u0ba3\u0bcd\u0b9f\u0bbe\u0bae\u0bcd  ? '\nprint(normalize_punct(s))\n# -&gt; \"\u0b87\u0ba4\u0bc1\" \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 ... \u0b9a\u0bb0\u0bbf! \u0b87\u0ba4\u0bc1 \u0b87\u0bb0\u0ba3\u0bcd\u0b9f\u0bbe\u0bae\u0bcd?\n</code></pre> <p>What it does</p> <ul> <li>Curly quotes \u2192 straight quotes</li> <li>Ellipsis <code>\u2026</code> \u2192 <code>...</code> (kept atomic)</li> <li>Collapses redundant whitespace</li> <li>No space before <code>. ! ? : ;</code> and closers</li> <li>Exactly one space after punctuation (unless end of line)</li> </ul>"},{"location":"corpus/#2-stable-de-duplication","title":"2) Stable de-duplication","text":"<pre><code>from tamil_utils.corpus import dedup_lines\n\nlines = [\"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP\\n\", \"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd nlp\\n\", \"  \u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP\\n\", \"Tamil nlp\\n\"]\nprint(dedup_lines(lines))\n# -&gt; ['\u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP\\n', 'Tamil nlp\\n']\n</code></pre> <p>Rules &amp; options</p> <ul> <li>First occurrence wins</li> <li><code>casefold=True</code>, <code>strip=True</code> by default (affects Latin; preserves originals)</li> <li>Call as <code>dedup_lines(lines, casefold=False, strip=False)</code> to disable either behavior</li> </ul>"},{"location":"corpus/#3-length-filters-chars-tokens","title":"3) Length filters (chars &amp; tokens)","text":"<pre><code>from tamil_utils.corpus import filter_by_length\n\ndata = [\"\u0b87\u0ba4\u0bc1\", \"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1\", \"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8\", \"\u0b9a\u0bb0\u0bbf!\"]\nout = list(filter_by_length(data, min_tokens=2, max_tokens=3))\nprint(out)\n# -&gt; ['\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1', '\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8']\n</code></pre> <p>Notes</p> <ul> <li>Tokenization uses <code>tamil_utils.tokens</code> after NFC normalize</li> <li> <p>Combine character and token bounds as needed:</p> </li> <li> <p><code>min_chars</code>, <code>max_chars</code></p> </li> <li><code>min_tokens</code>, <code>max_tokens</code></li> </ul>"},{"location":"corpus/#4-sentence-windows-for-rag","title":"4) Sentence windows for RAG","text":"<pre><code>from tamil_utils.corpus import window_sents\n\ntxt = \"\u0b87\u0ba4\u0bc1 \u0b92\u0ba9\u0bcd\u0bb1\u0bc1. \u0b87\u0ba4\u0bc1 \u0b87\u0bb0\u0ba3\u0bcd\u0b9f\u0bc1? \u0b9a\u0bb0\u0bbf! \u0bae\u0bc1\u0b9f\u0bbf\u0ba8\u0bcd\u0ba4\u0ba4\u0bc1.\"\nprint(window_sents(txt, k=2, stride=1))\n# -&gt; ['\u0b87\u0ba4\u0bc1 \u0b92\u0ba9\u0bcd\u0bb1\u0bc1. \u0b87\u0ba4\u0bc1 \u0b87\u0bb0\u0ba3\u0bcd\u0b9f\u0bc1?', '\u0b87\u0ba4\u0bc1 \u0b87\u0bb0\u0ba3\u0bcd\u0b9f\u0bc1? \u0b9a\u0bb0\u0bbf!', '\u0b9a\u0bb0\u0bbf! \u0bae\u0bc1\u0b9f\u0bbf\u0ba8\u0bcd\u0ba4\u0ba4\u0bc1.']\n</code></pre> <p>Why</p> <ul> <li>Joins <code>k</code> sentences per window with a sliding <code>stride</code></li> <li>Great for chunking long docs for retrieval pipelines</li> </ul>"},{"location":"corpus/#tips","title":"Tips","text":"<ul> <li>Use <code>normalize_punct</code> \u2192 <code>sents</code> \u2192 <code>window_sents</code> for clean, chunked inputs</li> <li>For PowerShell piping, prefer UTF-8 files or run <code>python -X utf8</code></li> </ul>"},{"location":"hf/","title":"Hugging Face Datasets (optional)","text":"<p><code>tamil-utils</code> can convert your preprocessed JSONL-like records into a Hugging Face <code>datasets.Dataset</code> and save/reload it for RAG/ML pipelines.</p> <p>Install when needed:</p> <p><code>bash pip install datasets</code></p>"},{"location":"hf/#from-python-records","title":"From Python records","text":"<pre><code>from tamil_utils.hf_export import to_hf_dataset, save_hf_dataset\n\nrecords = [\n    {\"text\": \"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 2025\", \"tokens\": [\"\u0b87\u0ba4\u0bc1\", \"\u0b92\u0bb0\u0bc1\", \"\u0b9a\u0bcb\u0ba4\u0ba9\u0bc8\", \"2025\"]},\n    {\"text\": \"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP\", \"tokens\": [\"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd\", \"NLP\"]},\n]\n\nds = to_hf_dataset(records)     # -&gt; datasets.Dataset\nsave_hf_dataset(ds, \"out_ds\")   # saves Arrow dataset to disk\n\n# later:\nimport datasets\nreloaded = datasets.load_from_disk(\"out_ds\")\nprint(len(reloaded), reloaded[0][\"text\"])\n</code></pre>"},{"location":"hf/#from-a-jsonl-preprocess-stream","title":"From a JSONL preprocess stream","text":"<p>First, build JSONL with the <code>tamil-utils</code> preprocessor:</p> <pre><code>python -m tamil_utils.cli preprocess --numerals ar --rmstop &lt; input.txt &gt; out.jsonl\n</code></pre> <p>Then load the JSONL into a Dataset:</p> <pre><code>import json\nfrom tamil_utils.hf_export import to_hf_dataset\n\nwith open(\"out.jsonl\", \"r\", encoding=\"utf-8\") as f:\n    records = (json.loads(line) for line in f if line.strip())\n\nds = to_hf_dataset(records)\nprint(ds)\n</code></pre>"},{"location":"hf/#tips","title":"Tips","text":"<ul> <li>Keep only the fields you need for training (e.g., <code>text</code>, <code>tokens</code>) to reduce disk/memory footprint.</li> <li>Keys in your JSON/records become columns in the resulting <code>datasets.Dataset</code>.</li> </ul>"},{"location":"ner/","title":"Named Entity Recognition (NER)","text":"<p><code>tamil-utils</code> includes a thin, Unicode-safe wrapper around a Hugging Face token-classification model (defaults to ai4bharat/IndicNER) and a tiny evaluation harness for quick checks on public datasets.</p> <p>Why this wrapper? You get NFC normalization, simple batch APIs, and consistent JSON outputs without touching transformers code. It\u2019s optional\u2014install only if you need NER.</p>"},{"location":"ner/#installation","title":"Installation","text":"<pre><code># core library\npip install tamil-utils\n\n# add NER extras (requires PyPI wheels for transformers/torch on your platform)\npip install \"tamil-utils[hf]\"\n# or explicitly:\n# pip install transformers datasets accelerate torch seqeval\n````\n\n---\n\n## Python API\n\n```python\nfrom tamil_utils.ner import NERTagger\n\ntagger = NERTagger()  # defaults to ai4bharat/IndicNER\nspans = tagger.predict_spans(\"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd\u0ba8\u0bbe\u0b9f\u0bc1 \u0b85\u0bb0\u0b9a\u0bc1 \u0b85\u0bb1\u0bbf\u0bb5\u0bbf\u0baa\u0bcd\u0baa\u0bc1 \u0b9a\u0bc6\u0ba9\u0bcd\u0ba9\u0bc8 \u0b87\u0ba9\u0bcd\u0bb1\u0bc1 \u0bb5\u0bc6\u0bb3\u0bbf\u0baf\u0bbe\u0ba9\u0ba4\u0bc1.\")\nfor s in spans:\n    print(s.label, s.text, s.start, s.end, f\"{s.score:.3f}\")\n\n# Or JSON-ready:\nprint(tagger.predict_json(\"\u0bb0\u0bbe\u0bae\u0bc1 TCS \u0ba8\u0bbf\u0bb1\u0bc1\u0bb5\u0ba9\u0ba4\u0bcd\u0ba4\u0bbf\u0bb2\u0bcd \u0b9a\u0bc6\u0ba9\u0bcd\u0ba9\u0bc8 \u0b85\u0bb2\u0bc1\u0bb5\u0bb2\u0b95\u0ba4\u0bcd\u0ba4\u0bbf\u0bb2\u0bcd \u0b89\u0bb3\u0bcd\u0bb3\u0bbe\u0bb0\u0bcd.\"))\n</code></pre> <p>Batching</p> <pre><code>texts = [\n    \"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd\u0ba8\u0bbe\u0b9f\u0bc1 \u0b85\u0bb0\u0b9a\u0bc1 \u0b85\u0bb1\u0bbf\u0bb5\u0bbf\u0baa\u0bcd\u0baa\u0bc1 \u0b9a\u0bc6\u0ba9\u0bcd\u0ba9\u0bc8 \u0b87\u0ba9\u0bcd\u0bb1\u0bc1 \u0bb5\u0bc6\u0bb3\u0bbf\u0baf\u0bbe\u0ba9\u0ba4\u0bc1.\",\n    \"\u0bb0\u0bbe\u0bae\u0bc1 TCS \u0ba8\u0bbf\u0bb1\u0bc1\u0bb5\u0ba9\u0ba4\u0bcd\u0ba4\u0bbf\u0bb2\u0bcd \u0b9a\u0bc6\u0ba9\u0bcd\u0ba9\u0bc8 \u0b85\u0bb2\u0bc1\u0bb5\u0bb2\u0b95\u0ba4\u0bcd\u0ba4\u0bbf\u0bb2\u0bcd \u0b89\u0bb3\u0bcd\u0bb3\u0bbe\u0bb0\u0bcd.\",\n]\nbatched = tagger.predict_spans_batch(texts)\n</code></pre>"},{"location":"ner/#cli","title":"CLI","text":"<pre><code># Single input (or pipe via stdin)\npython -m tamil_utils.cli ner \"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd\u0ba8\u0bbe\u0b9f\u0bc1 \u0b85\u0bb0\u0b9a\u0bc1 \u0b85\u0bb1\u0bbf\u0bb5\u0bbf\u0baa\u0bcd\u0baa\u0bc1 \u0b9a\u0bc6\u0ba9\u0bcd\u0ba9\u0bc8 \u0b87\u0ba9\u0bcd\u0bb1\u0bc1 \u0bb5\u0bc6\u0bb3\u0bbf\u0baf\u0bbe\u0ba9\u0ba4\u0bc1.\"\n\n# Use a different model, or force CPU with --device -1\npython -m tamil_utils.cli ner --model ai4bharat/IndicNER --device -1 \"\u0bb0\u0bbe\u0bae\u0bc1 TCS \u0ba8\u0bbf\u0bb1\u0bc1\u0bb5\u0ba9\u0ba4\u0bcd\u0ba4\u0bbf\u0bb2\u0bcd ...\"\n\n# Quick evaluation harness (Naamapadam sample; prints JSONL to stdout)\npython -m tamil_utils.cli eval-ner --limit 50 --split validation --lang ta\n# save predictions\npython -m tamil_utils.cli eval-ner --limit 50 --save-jsonl preds.jsonl\n</code></pre> <p>Outputs (example)</p> <pre><code>[\n  {\"label\":\"LOC\",\"text\":\"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd\u0ba8\u0bbe\u0b9f\u0bc1\",\"start\":0,\"end\":9,\"score\":0.98},\n  {\"label\":\"LOC\",\"text\":\"\u0b9a\u0bc6\u0ba9\u0bcd\u0ba9\u0bc8\",\"start\":24,\"end\":31,\"score\":0.97},\n  {\"label\":\"ORG\",\"text\":\"TCS\",\"start\":6,\"end\":9,\"score\":0.95}\n]\n</code></pre>"},{"location":"ner/#notes-tips","title":"Notes &amp; tips","text":"<ul> <li>Models &amp; data   Default model is ai4bharat/IndicNER (multilingual Indic NER). The evaluation   harness samples from Naamapadam (large Indic NER dataset).</li> <li>Normalization   The wrapper runs <code>normalize()</code> before inference to avoid Unicode edge-cases.</li> <li>Performance   For CPU-only environments, set <code>--device -1</code>. For GPU, pass CUDA index (e.g., <code>--device 0</code>).</li> <li>Licensing &amp; usage   Check model/data cards for licenses before shipping to production.</li> </ul>"},{"location":"ner/#troubleshooting","title":"Troubleshooting","text":"<ul> <li><code>transformers</code> not found \u2192 install extras: <code>pip install \"tamil-utils[hf]\"</code>.</li> <li>Torch/accelerate wheels missing \u2192 install a version compatible with your Python/OS/CPU/GPU.</li> <li>Slow cold start \u2192 first run downloads model weights; reuse the same environment to avoid re-downloads.</li> </ul>"},{"location":"ner/#minimal-recipe-ner-rag","title":"Minimal recipe: NER \u2192 RAG","text":"<ol> <li>Preprocess a corpus (normalize, sentence-split),</li> <li>Run <code>ner</code> to extract entities per sentence,</li> <li>Store <code>{text, entities}</code> in an index (e.g., JSONL \u2192 FAISS/Chroma/HF Datasets),</li> <li>Use entities as filters or boosts for retrieval.</li> </ol> <pre><code># toy example: one document per line; get top entities per sentence window\npython -m tamil_utils.cli corpus-windows --k 3 --stride 1 --file docs.txt \\\n| python -m tamil_utils.cli ner --device -1 \\\n&gt; windows_ner.jsonl\n</code></pre>"},{"location":"preprocess/","title":"Dataset Preprocessor (JSONL-friendly)","text":"<p>The <code>preprocess</code> tools help you clean, segment, and tokenize Tamil text in a stream-friendly way for RAG/ML pipelines.</p>"},{"location":"preprocess/#what-it-does","title":"What it does","text":"<ul> <li>Normalize text to NFC and optionally harmonize numerals</li> <li>Sentence split (<code>sents</code>)</li> <li>Tokenize (<code>tokens</code>)</li> <li>Optional stopword removal (<code>tokens_nostop</code>, Tamil preset)</li> </ul> <p>One JSON object per input line \u2192 ideal for JSONL.</p>"},{"location":"preprocess/#python-api","title":"Python API","text":"<pre><code>from tamil_utils.preprocess import (\n    PreprocessOptions, preprocess_record, preprocess_lines\n)\n\nopts = PreprocessOptions(numerals=\"ar\", rmstop=True)\nrec = preprocess_record(\"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 \u0be8\u0be6\u0be8\u0beb\", opts)\nprint(rec)\n# {\n#   \"text\": \"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 2025\",\n#   \"sents\": [\"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 2025\"],\n#   \"tokens\": [\"\u0b87\u0ba4\u0bc1\",\"\u0b92\u0bb0\u0bc1\",\"\u0b9a\u0bcb\u0ba4\u0ba9\u0bc8\",\"2025\"],\n#   \"tokens_nostop\": [\"\u0b9a\u0bcb\u0ba4\u0ba9\u0bc8\",\"2025\"]\n# }\n\n# Stream lines \u2192 records\nwith open(\"input.txt\", \"r\", encoding=\"utf-8\") as f:\n    for r in preprocess_lines(f, opts):\n        print(r)\n</code></pre> <p>Example record (JSON):</p> <pre><code>{\n  \"text\": \"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 2025\",\n  \"sents\": [\"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 2025\"],\n  \"tokens\": [\"\u0b87\u0ba4\u0bc1\", \"\u0b92\u0bb0\u0bc1\", \"\u0b9a\u0bcb\u0ba4\u0ba9\u0bc8\", \"2025\"],\n  \"tokens_nostop\": [\"\u0b9a\u0bcb\u0ba4\u0ba9\u0bc8\", \"2025\"]\n}\n</code></pre>"},{"location":"preprocess/#cli","title":"CLI","text":"<pre><code># stdin \u2192 stdout (JSONL)\npython -m tamil_utils.cli preprocess --numerals ar --rmstop &lt; input.txt &gt; out.jsonl\n\n# Select fields to emit (subset of: text,sents,tokens,tokens_nostop)\npython -m tamil_utils.cli preprocess --emit text,tokens &lt; input.txt &gt; out.jsonl\n</code></pre>"},{"location":"preprocess/#powershell-note-windows","title":"PowerShell note (Windows)","text":"<p>When piping Tamil text, prefer a UTF-8 file or use <code>python -X utf8</code>:</p> <pre><code>Set-Content -Path in.txt -Value '\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 \u0be8\u0be6\u0be8\u0beb' -Encoding UTF8\nGet-Content -Raw -Encoding UTF8 .\\in.txt | python -X utf8 -m tamil_utils.cli preprocess --numerals ar --rmstop\n</code></pre>"},{"location":"preprocess/#options","title":"Options","text":"<ul> <li> <p><code>numerals</code></p> </li> <li> <p><code>ar</code> \u2192 Tamil digits \u2192 ASCII (e.g., \u0be8\u0be6\u0be8\u0beb \u2192 2025)</p> </li> <li><code>ta</code> \u2192 ASCII \u2192 Tamil digits (e.g., 123 \u2192 \u0be7\u0be8\u0be9)</li> <li><code>rmstop</code> \u2013 also emit <code>tokens_nostop</code> (Tamil preset)</li> <li><code>emit</code> \u2013 comma-separated fields to include (<code>text,sents,tokens,tokens_nostop</code>)</li> </ul>"},{"location":"preprocess/#output-schema","title":"Output Schema","text":"<p>Each processed record is a JSON object:</p> Field Type Description <code>text</code> string Normalized (NFC) text with optional numeral mapping <code>sents</code> string[] Sentence segments <code>tokens</code> string[] Word tokens <code>tokens_nostop</code> string[] (opt.) Tokens with Tamil stopwords removed (if <code>rmstop</code>)"},{"location":"preprocess/#when-to-use","title":"When to use","text":"<ul> <li>Preparing corpora for RAG / LLM fine-tuning</li> <li>Building JSONL datasets (one line per record)</li> <li>Quick, dependency-free preprocessing in data pipelines</li> </ul>"},{"location":"recipes/","title":"Recipes","text":"<p>Copy-pasteable pipelines for apps, data prep, and RAG.</p>"},{"location":"recipes/#1-quick-clean-jsonl-cli","title":"1) Quick clean \u2192 JSONL (CLI)","text":"<pre><code># Normalize punctuation, then preprocess to JSONL with numerals harmonized\n# One record per line: {\"text\",\"sents\",\"tokens\",\"tokens_nostop\"}\npython -m tamil_utils.cli preprocess --numerals ar --rmstop &lt; input.txt &gt; out.jsonl\n</code></pre> <p>Tip (Windows PowerShell, UTF-8):</p> <pre><code>Set-Content in.txt -Value '\u201c\u0b87\u0ba4\u0bc1\u201d  \u0b92\u0bb0\u0bc1  \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 \u2026  \u0b9a\u0bb0\u0bbf!' -Encoding UTF8\nGet-Content -Raw -Encoding UTF8 .\\in.txt | python -X utf8 -m tamil_utils.cli preprocess --numerals ar --rmstop\n</code></pre>"},{"location":"recipes/#2-deduplicate-filter-before-preprocessing-cli","title":"2) Deduplicate + filter before preprocessing (CLI)","text":"<pre><code># Remove duplicates (stable order)\npython -m tamil_utils.cli corpus-dedup --file raw.txt &gt; uniq.txt\n\n# Keep medium-sized lines (2\u201350 tokens)\npython -m tamil_utils.cli corpus-filter --file uniq.txt --min-tokens 2 --max-tokens 50 &gt; kept.txt\n\n# Convert to JSONL records\npython -m tamil_utils.cli preprocess --numerals ar --rmstop &lt; kept.txt &gt; data.jsonl\n</code></pre>"},{"location":"recipes/#3-rag-chunks-via-sentence-windows-cli","title":"3) RAG chunks via sentence windows (CLI)","text":"<pre><code># Windows of 3 sentences with stride 1 (overlapping chunks)\npython -m tamil_utils.cli corpus-windows --k 3 --stride 1 --file doc.txt &gt; chunks.txt\n\n# (optional) Further normalize / tokenize per chunk\npython -m tamil_utils.cli preprocess --numerals ar --rmstop &lt; chunks.txt &gt; chunks.jsonl\n</code></pre>"},{"location":"recipes/#4-end-to-end-in-python-clean-window-hf-dataset","title":"4) End-to-end in Python: clean \u2192 window \u2192 HF Dataset","text":"<pre><code>import json\nfrom tamil_utils.corpus import normalize_punct, window_sents\nfrom tamil_utils.preprocess import PreprocessOptions, preprocess_record\nfrom tamil_utils.hf_export import to_hf_dataset  # pip install datasets\n\ntext = ' \u201c\u0b87\u0ba4\u0bc1\u201d  \u0b92\u0bb0\u0bc1  \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 \u2026  \u0b9a\u0bb0\u0bbf! \u0b87\u0ba4\u0bc1 \u0b87\u0bb0\u0ba3\u0bcd\u0b9f\u0bbe\u0bae\u0bcd? '\nclean = normalize_punct(text)\nwins = window_sents(clean, k=2, stride=1)     # sentence windows\n\nopts = PreprocessOptions(numerals=\"ar\", rmstop=True, emit=[\"text\",\"tokens\",\"tokens_nostop\"])\nrecords = [preprocess_record(w, opts) for w in wins]\n\nds = to_hf_dataset(records)\nprint(ds)\n# save to disk for training later:\n#   from tamil_utils.hf_export import save_hf_dataset\n#   save_hf_dataset(ds, \"out_ds\")\n</code></pre>"},{"location":"recipes/#5-minimal-training-jsonl-keep-only-text","title":"5) Minimal training JSONL (keep only <code>\"text\"</code>)","text":"<p>If you only need <code>text</code> for LM/RAG ingestion:</p> <pre><code>python -m tamil_utils.cli preprocess --numerals ar --emit text &lt; input.txt &gt; text_only.jsonl\n</code></pre> <p>Each line:</p> <pre><code>{\"text\": \"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 2025\"}\n</code></pre>"},{"location":"recipes/#6-spacy-tokenizer-hook-optional","title":"6) spaCy tokenizer hook (optional)","text":"<p>Mirror <code>tamil_utils.tokens</code> inside spaCy:</p> <pre><code>import spacy\nfrom tamil_utils.spacy_hook import install_tamil_tokenizer\n\nnlp = spacy.blank(\"xx\")            # language-agnostic\ninstall_tamil_tokenizer(nlp)       # NFC-normalizes and replaces tokenizer\ndoc = nlp(\"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 2025\")\nprint([t.text for t in doc])       # ['\u0b87\u0ba4\u0bc1','\u0b92\u0bb0\u0bc1','\u0b9a\u0bcb\u0ba4\u0ba9\u0bc8','2025']\n</code></pre> <p>Install:</p> <pre><code>pip install \"tamil-utils[spacy]\"\n</code></pre>"},{"location":"recipes/#7-n-gram-counts-for-quick-analysis","title":"7) N-gram counts for quick analysis","text":"<pre><code>python -m tamil_utils.cli freq -n 1 --top 20 \"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP \u0ba4\u0bae\u0bbf\u0bb4\u0bcd \u0baa\u0baf\u0ba9\u0bcd\u0baa\u0bbe\u0b9f\u0bc1\"\npython -m tamil_utils.cli freq -n 2 --top 10 \"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP \u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP\"\n</code></pre> <p>Programmatically:</p> <pre><code>from tamil_utils import word_counts\nprint(word_counts(\"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP \u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP\", n=2, top=3))\n</code></pre>"},{"location":"recipes/#8-sorting-titles-in-tamil-order","title":"8) Sorting titles in Tamil order","text":"<pre><code>from tamil_utils import sort_tamil\ntitles = [\"\u0b87\u0bb2\u0b99\u0bcd\u0b95\u0bc8\", \"\u0b86\u0ba4\u0bbf\", \"\u0b85\u0b9f\u0bbf\"]\nprint(sort_tamil(titles))  # ['\u0b85\u0b9f\u0bbf', '\u0b86\u0ba4\u0bbf', '\u0b87\u0bb2\u0b99\u0bcd\u0b95\u0bc8']\n</code></pre> <p>For strict, locale-aware collation (libraries, catalogs), use ICU (<code>PyICU</code>) and fallback to <code>sort_tamil</code>.</p>"},{"location":"recipes/#9-common-gotchas","title":"9) Common gotchas","text":"<ul> <li>Encoding: prefer UTF-8 files and <code>python -X utf8</code> when piping on Windows.</li> <li>Normalization: mixed corpora benefit from <code>normalize_punct</code> before <code>sents</code>/<code>window_sents</code>.</li> <li>Stopwords: Tamil preset is pragmatic, not exhaustive\u2014tune for your domain.</li> </ul>"},{"location":"recipes/#10-tiny-checklists","title":"10) Tiny checklists","text":"<p>RAG prep (docs \u2192 chunks \u2192 JSONL):</p> <ol> <li><code>normalize_punct(doc)</code></li> <li><code>window_sents(..., k=3, stride=1)</code></li> <li><code>preprocess_record(chunk, numerals='ar', rmstop=True)</code></li> <li>(optional) <code>to_hf_dataset(records)</code></li> </ol> <p>Corpus cleanup (CLI):</p> <pre><code>python -m tamil_utils.cli corpus-dedup --file raw.txt \\\n| python -m tamil_utils.cli corpus-filter --min-tokens 2 --max-tokens 50 \\\n| python -m tamil_utils.cli preprocess --numerals ar --rmstop &gt; data.jsonl\n</code></pre>"},{"location":"spacy/","title":"spaCy Tokenizer Hook (optional)","text":"<p><code>tamil-utils</code> can install a Tamil-aware spaCy tokenizer so tokenization matches <code>tamil_utils.tokens</code>. It also normalizes input to Unicode NFC.</p>"},{"location":"spacy/#quick-start","title":"Quick start","text":"<pre><code>import spacy\nfrom tamil_utils.spacy_hook import install_tamil_tokenizer\n\nnlp = spacy.blank(\"xx\")           # use spaCy's multi-language pipeline\ninstall_tamil_tokenizer(nlp)      # replaces nlp.tokenizer; normalizes to NFC\n\ndoc = nlp(\"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 2025\")\nprint([t.text for t in doc])      # ['\u0b87\u0ba4\u0bc1','\u0b92\u0bb0\u0bc1','\u0b9a\u0bcb\u0ba4\u0ba9\u0bc8','2025']\n</code></pre>"},{"location":"spacy/#install","title":"Install","text":"<pre><code>pip install \"spacy&gt;=3.6,&lt;4\"\n# or, if you've enabled extras in your pyproject:\npip install \"tamil-utils[spacy]\"\n</code></pre>"},{"location":"spacy/#notes","title":"Notes","text":"<ul> <li>Language: <code>spacy.blank(\"xx\")</code> (multi-language) is recommended.   If you already have a pipeline (e.g., <code>en_core_web_sm</code>), call <code>install_tamil_tokenizer(nlp)</code> after loading it to replace its tokenizer.</li> <li>What it changes: Only <code>nlp.tokenizer</code> is replaced. Other pipeline components (tagger, parser, etc.) are untouched.</li> <li>Normalization: Text is normalized to NFC before tokenization to ensure consistent Tamil segmentation.</li> </ul>"},{"location":"spacy/#restore-default-tokenizer-optional","title":"Restore default tokenizer (optional)","text":"<p>If you need to revert to spaCy\u2019s default tokenizer:</p> <pre><code>from spacy.tokenizer import Tokenizer\nnlp.tokenizer = Tokenizer(nlp.vocab)\n</code></pre>"},{"location":"tanglish/","title":"Tanglish","text":"<pre><code># Tanglish (Tamil in Latin script)\n\nMany real-world texts mix Tamil script with **Tamil written in Latin letters** (a.k.a. *Tanglish*):  \n&gt; \u201cenna solra idhu sariyaa? Tamil ok-aa?\u201d\n\n`tamil-utils` provides:\n- **Detection/tagging** of Tanglish tokens (dependency-free)\n- **Optional transliteration** of Tanglish \u2192 Tamil (via plugin)\n\nThis improves downstream **NER, search, RAG, and analytics** by normalizing noisy inputs.\n\n---\n\n## Install\n\n```bash\n# Core library (no heavy deps)\npip install tamil-utils\n\n# Optional: enable Tanglish \u2192 Tamil transliteration\npip install aksharamukha-transliterate   # plugin used by tamil-utils\n</code></pre> <p>If the plugin is missing, transliteration silently falls back to a no-op. Detection/tagging works without any extra packages.</p>"},{"location":"tanglish/#quick-start-cli","title":"Quick start (CLI)","text":""},{"location":"tanglish/#detectmark-tanglish-tokens","title":"Detect/mark Tanglish tokens","text":"<pre><code>python -m tamil_utils.cli tanglish-tag \"enna solra? \u0ba4\u0bae\u0bbf\u0bb4\u0bcd ok-aa?\"\n# \u2192 \u27eaenna\u27eb \u27easolra\u27eb? \u0ba4\u0bae\u0bbf\u0bb4\u0bcd \u27eaok\u27eb-\u27eaaa\u27eb?\n</code></pre>"},{"location":"tanglish/#transliterate-tanglish-tamil-if-plugin-installed","title":"Transliterate Tanglish \u2192 Tamil (if plugin installed)","text":"<pre><code>python -m tamil_utils.cli tanglish-2ta \"enna solra idhu sariyaa?\"\n# \u2192 \u0b8e\u0ba9\u0bcd\u0ba9 \u0b9a\u0bca\u0bb2\u0bcd\u0bb1 \u0b87\u0ba4\u0bc1 \u0b9a\u0bb0\u0bbf\u0baf\u0bbe?   (best-effort; depends on input style)\n</code></pre> <p>Windows UTF-8 tip for pipes</p> <pre><code>chcp 65001 &gt; $null; [Console]::InputEncoding=[Text.Encoding]::UTF8; [Console]::OutputEncoding=[Text.Encoding]::UTF8\n$env:PYTHONIOENCODING=\"utf-8\"\n</code></pre>"},{"location":"tanglish/#python-api","title":"Python API","text":"<pre><code>from tamil_utils.tanglish import detect_tanglish, normalize_tanglish, tanglish_to_tamil\n\ntxt = \"enna solra? \u0ba4\u0bae\u0bbf\u0bb4\u0bcd ok-aa?\"\ntags = detect_tanglish(txt)\n# [(\"enna\",\"Tanglish\"), (\" \",\"Other\"), (\"solra\",\"Tanglish\"), (\"?\",\"Other\"), (\" \",\"Other\"),\n#  (\"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd\",\"Tamil\"), (\" \",\"Other\"), (\"ok\",\"Tanglish\"), (\"-\",\"Other\"), (\"aa\",\"Tanglish\"), (\"?\",\"Other\")]\n\n# Debug/tag mode (wrap Tanglish tokens with \u27ea \u27eb)\nprint(normalize_tanglish(txt, mode=\"tag\"))\n# \u27eaenna\u27eb \u27easolra\u27eb? \u0ba4\u0bae\u0bbf\u0bb4\u0bcd \u27eaok\u27eb-\u27eaaa\u27eb?\n\n# Transliterate Tanglish \u2192 Tamil (requires aksharamukha-transliterate)\nprint(tanglish_to_tamil(\"enna solra idhu sariyaa?\"))\n</code></pre>"},{"location":"tanglish/#modes","title":"Modes","text":"<ul> <li> <p><code>mode=\"tag\"</code>: Non-destructive; wraps Tanglish tokens as <code>\u27eatoken\u27eb</code>.   Use for inspection or to branch pipeline logic.</p> </li> <li> <p><code>mode=\"transliterate\"</code>: Converts Tanglish tokens to Tamil using a plugin   (default: Aksharamukha, if installed). Tokens not recognized or plugin-less inputs are left as-is.</p> </li> </ul>"},{"location":"tanglish/#heuristics-detection","title":"Heuristics (detection)","text":"<p>A token is marked Tanglish if:</p> <ul> <li>It is pure Latin (no Tamil codepoints), contains a vowel, and</li> <li>Matches common romanization cues: <code>aa</code> <code>ee</code> <code>oo</code> <code>uu</code>, <code>zh</code> (\u0bb4), <code>ng</code>, <code>ny</code>, <code>th</code>/<code>dh</code>, <code>ai</code>, <code>au</code>, etc.</li> </ul> <p>These rules are intentionally conservative and language-aware (Tamil vs generic Latin).</p>"},{"location":"tanglish/#quality-caveats","title":"Quality &amp; caveats","text":"<ul> <li>Transliteration is best-effort. Colloquial spellings vary; perfect 1-1 mapping isn\u2019t guaranteed.</li> <li>Acronyms, brand names, or English words in Latin remain Latin (not Tanglish) unless they look like Tamil romanization.</li> <li>Keep a human review loop for high-stakes pipelines (e.g., legal/government documents).</li> </ul>"},{"location":"tanglish/#recipes","title":"Recipes","text":""},{"location":"tanglish/#1-clean-detect-transliterate-preprocess","title":"1) Clean \u2192 detect \u2192 transliterate \u2192 preprocess","text":"<pre><code># Example: sentence windows with normalized Tanglish, then NER\ncat docs.txt \\\n| python -m tamil_utils.cli tanglish-2ta \\\n| python -m tamil_utils.cli corpus-windows --k 3 --stride 1 \\\n| python -m tamil_utils.cli ner --device -1 \\\n&gt; windows_ner.jsonl\n</code></pre>"},{"location":"tanglish/#2-branch-by-tag-density-python","title":"2) Branch by tag density (Python)","text":"<pre><code>from tamil_utils.tanglish import detect_tanglish, tanglish_to_tamil\nfrom tamil_utils import preprocess\n\ns = \"enna solra? \u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8\"\npairs = detect_tanglish(s)\ntanglish_ratio = sum(1 for _, t in pairs if t==\"Tanglish\") / max(1, sum(1 for _, t in pairs if _.strip()))\nif tanglish_ratio &gt; 0.2:\n    s = tanglish_to_tamil(s)  # normalize only if heavy Tanglish\nrec = preprocess.preprocess_record(s)\n</code></pre>"},{"location":"tanglish/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Transliteration didn\u2019t change text \u2192 install plugin:</li> </ul> <p><code>bash   pip install aksharamukha-transliterate</code> * Mixed Tamil+Latin words may be tagged <code>Other</code> (not transliterated).   Consider splitting punctuation and retrying, or rely on <code>preprocess</code> tokens.</p>"},{"location":"tanglish/#see-also","title":"See also","text":"<ul> <li>Preprocess \u2013 normalization \u2192 sentences \u2192 tokens \u2192 numerals/stopwords</li> <li>NER \u2013 entity extraction for Tamil (IndicNER wrapper)</li> </ul> <p>````</p>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#quickstart","title":"Quickstart","text":"<pre><code>pip install tamil-utils\n\npython -m tamil_utils.cli sents \"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0bb5\u0bbe\u0b95\u0bcd\u0b95\u0bbf\u0baf\u0bae\u0bcd. \u0b87\u0ba4\u0bc1 \u0b87\u0bb0\u0ba3\u0bcd\u0b9f\u0bbe\u0bae\u0bcd? \u0b9a\u0bb0\u0bbf!\"\npython -m tamil_utils.cli to-iso \"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd\"\npython -m tamil_utils.cli script \"\u0b87\u0ba8\u0bcd\u0ba4 text code-mixed \u0b86\u0b95 \u0b87\u0bb0\u0bc1\u0b95\u0bcd\u0b95\u0bc1\u0bae\u0bcd\"\n</code></pre>"}]}