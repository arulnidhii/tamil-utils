{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"tamil-utils","text":"<p>Small, production-ready Tamil-first text layer.</p> <ul> <li>Normalization &amp; graphemes</li> <li>Tamil-aware tokens</li> <li>Stopwords preset, sentence splitter, numerals</li> <li>v0.1 adds: script detection, ISO-15919 transliteration</li> </ul>"},{"location":"api/","title":"API","text":"<pre><code>mkdocs serve\n</code></pre>"},{"location":"collation/","title":"Collation (Sorting) for Tamil","text":"<p><code>tamil-utils</code> provides a lightweight collation via <code>sort_tamil()</code>. It builds a stable sort key from ISO-15919 transliteration so words sort roughly as native Tamil order:</p> <p>a &lt; \u0101 &lt; i &lt; \u012b &lt; u &lt; \u016b &lt; e &lt; \u0113 &lt; ai &lt; o &lt; \u014d &lt; au</p> <p>This is deterministic and dependency-free, suitable for most app and data tasks. It is not a full Tamil Collation Algorithm (TCA) and does not depend on ICU.</p>"},{"location":"collation/#quick-usage","title":"Quick usage","text":"<pre><code>from tamil_utils import sort_tamil\n\nwords = [\"\u0b87\u0bb2\u0b99\u0bcd\u0b95\u0bc8\", \"\u0b86\u0ba4\u0bbf\", \"\u0b85\u0b9f\u0bbf\"]\nprint(sort_tamil(words))   # ['\u0b85\u0b9f\u0bbf', '\u0b86\u0ba4\u0bbf', '\u0b87\u0bb2\u0b99\u0bcd\u0b95\u0bc8']\n\nYes. That section **is part of `docs/collation.md`** right after \u201cQuick usage\u201d.\n\nHere\u2019s the exact block to paste (properly fenced):\n\n````markdown\n## When you need strict, locale-aware collation\n\nIf your product requires exact linguistic collation for Tamil (e.g., official indexes, libraries), use **ICU** where available and fall back to `sort_tamil()`.\n\n### Python (PyICU) with fallback\n\n```python\ndef sort_tamil_strict(words):\n    try:\n        from icu import Collator, Locale\n        coll = Collator.createInstance(Locale(\"ta_IN\"))\n        return sorted(words, key=coll.getSortKey)\n    except Exception:\n        from tamil_utils import sort_tamil\n        return sort_tamil(words)\n\nwords = [\"\u0b87\u0bb2\u0b99\u0bcd\u0b95\u0bc8\", \"\u0b86\u0ba4\u0bbf\", \"\u0b85\u0b9f\u0bbf\"]\nprint(sort_tamil_strict(words))\n````\n\n&gt; Install: `pip install PyICU` (platform-specific wheels may apply).\n&gt; Keep `tamil-utils` default lightweight; add ICU only if your deployment needs it.\n\n</code></pre> <p>If your markdown preview was showing it mangled, it\u2019s usually because the inner Python block wasn\u2019t fenced correctly\u2014use the triple backticks as above. ::contentReference[oaicite:0]{index=0} ```</p>"},{"location":"preprocess/","title":"Dataset Preprocessor (JSONL-friendly)","text":"<p>The <code>preprocess</code> tools help you clean, segment, and tokenize Tamil text in a stream-friendly way for RAG/ML pipelines.</p>"},{"location":"preprocess/#what-it-does","title":"What it does","text":"<ul> <li>Normalize text to NFC and optionally harmonize numerals</li> <li>Sentence split (<code>sents</code>)</li> <li>Tokenize (<code>tokens</code>)</li> <li>Optional stopword removal (<code>tokens_nostop</code>, Tamil preset)</li> </ul> <p>One JSON object per input line \u2192 ideal for JSONL.</p>"},{"location":"preprocess/#python-api","title":"Python API","text":"<pre><code>from tamil_utils.preprocess import (\n    PreprocessOptions, preprocess_record, preprocess_lines\n)\n\nopts = PreprocessOptions(numerals=\"ar\", rmstop=True)\nrec = preprocess_record(\"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 \u0be8\u0be6\u0be8\u0beb\", opts)\nprint(rec)\n# {\n#   \"text\": \"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 2025\",\n#   \"sents\": [\"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 2025\"],\n#   \"tokens\": [\"\u0b87\u0ba4\u0bc1\",\"\u0b92\u0bb0\u0bc1\",\"\u0b9a\u0bcb\u0ba4\u0ba9\u0bc8\",\"2025\"],\n#   \"tokens_nostop\": [\"\u0b9a\u0bcb\u0ba4\u0ba9\u0bc8\",\"2025\"]\n# }\n\n# Stream lines \u2192 records\nwith open(\"input.txt\", \"r\", encoding=\"utf-8\") as f:\n    for r in preprocess_lines(f, opts):\n        print(r)\n</code></pre> <p>Example record (JSON):</p> <pre><code>{\n  \"text\": \"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 2025\",\n  \"sents\": [\"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 2025\"],\n  \"tokens\": [\"\u0b87\u0ba4\u0bc1\", \"\u0b92\u0bb0\u0bc1\", \"\u0b9a\u0bcb\u0ba4\u0ba9\u0bc8\", \"2025\"],\n  \"tokens_nostop\": [\"\u0b9a\u0bcb\u0ba4\u0ba9\u0bc8\", \"2025\"]\n}\n</code></pre>"},{"location":"preprocess/#cli","title":"CLI","text":"<pre><code># stdin \u2192 stdout (JSONL)\npython -m tamil_utils.cli preprocess --numerals ar --rmstop &lt; input.txt &gt; out.jsonl\n\n# Select fields to emit (subset of: text,sents,tokens,tokens_nostop)\npython -m tamil_utils.cli preprocess --emit text,tokens &lt; input.txt &gt; out.jsonl\n</code></pre>"},{"location":"preprocess/#powershell-note-windows","title":"PowerShell note (Windows)","text":"<p>When piping Tamil text, prefer a UTF-8 file or use <code>python -X utf8</code>:</p> <pre><code>Set-Content -Path in.txt -Value '\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 \u0be8\u0be6\u0be8\u0beb' -Encoding UTF8\nGet-Content -Raw -Encoding UTF8 .\\in.txt | python -X utf8 -m tamil_utils.cli preprocess --numerals ar --rmstop\n</code></pre>"},{"location":"preprocess/#options","title":"Options","text":"<ul> <li> <p><code>numerals</code></p> </li> <li> <p><code>ar</code> \u2192 Tamil digits \u2192 ASCII (e.g., \u0be8\u0be6\u0be8\u0beb \u2192 2025)</p> </li> <li><code>ta</code> \u2192 ASCII \u2192 Tamil digits (e.g., 123 \u2192 \u0be7\u0be8\u0be9)</li> <li><code>rmstop</code> \u2013 also emit <code>tokens_nostop</code> (Tamil preset)</li> <li><code>emit</code> \u2013 comma-separated fields to include (<code>text,sents,tokens,tokens_nostop</code>)</li> </ul>"},{"location":"preprocess/#output-schema","title":"Output Schema","text":"<p>Each processed record is a JSON object:</p> Field Type Description <code>text</code> string Normalized (NFC) text with optional numeral mapping <code>sents</code> string[] Sentence segments <code>tokens</code> string[] Word tokens <code>tokens_nostop</code> string[] (opt.) Tokens with Tamil stopwords removed (if <code>rmstop</code>)"},{"location":"preprocess/#when-to-use","title":"When to use","text":"<ul> <li>Preparing corpora for RAG / LLM fine-tuning</li> <li>Building JSONL datasets (one line per record)</li> <li>Quick, dependency-free preprocessing in data pipelines</li> </ul>"},{"location":"recipes/","title":"Examples &amp; Recipes","text":"<p>A few practical \u201ccopy-paste\u201d workflows for <code>tamil-utils</code>.</p>"},{"location":"recipes/#1-clean-tokenize-stopwords-n-grams-frequency-sort","title":"1) Clean \u2192 Tokenize \u2192 Stopwords \u2192 N-grams \u2192 Frequency \u2192 Sort","text":""},{"location":"recipes/#python","title":"Python","text":"<pre><code>from tamil_utils import tokens, remove_stopwords, ngrams, word_counts, sort_tamil\n\ntext = \"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP \u0ba4\u0bae\u0bbf\u0bb4\u0bcd \u0baa\u0baf\u0ba9\u0bcd\u0baa\u0bbe\u0b9f\u0bc1 \u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP\"\n\ntok = tokens(text)\ntok_nostop = remove_stopwords(tok, preset=\"ta\")\n\n# bigrams\nbigs = [\" \".join(g) for g in ngrams(tok_nostop, 2)]\nprint(bigs)\n\n# top-2 bigrams by frequency\nprint(word_counts(text, n=2, top=2))\n\n# sort Tamil words (lightweight collation)\nprint(sort_tamil([\"\u0b87\u0bb2\u0b99\u0bcd\u0b95\u0bc8\", \"\u0b86\u0ba4\u0bbf\", \"\u0b85\u0b9f\u0bbf\"]))\n</code></pre>"},{"location":"recipes/#cli","title":"CLI","text":"<pre><code>python -m tamil_utils.cli tokens --rmstop \"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP \u0ba4\u0bae\u0bbf\u0bb4\u0bcd \u0baa\u0baf\u0ba9\u0bcd\u0baa\u0bbe\u0b9f\u0bc1 \u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP\"\npython -m tamil_utils.cli ngrams -n 2 \"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP \u0ba4\u0bae\u0bbf\u0bb4\u0bcd \u0baa\u0baf\u0ba9\u0bcd\u0baa\u0bbe\u0b9f\u0bc1 \u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP\"\npython -m tamil_utils.cli freq -n 2 --top 2 \"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP \u0ba4\u0bae\u0bbf\u0bb4\u0bcd \u0baa\u0baf\u0ba9\u0bcd\u0baa\u0bbe\u0b9f\u0bc1 \u0ba4\u0bae\u0bbf\u0bb4\u0bcd NLP\"\npython -m tamil_utils.cli sort \u0b87\u0bb2\u0b99\u0bcd\u0b95\u0bc8 \u0b86\u0ba4\u0bbf \u0b85\u0b9f\u0bbf\n</code></pre>"},{"location":"recipes/#2-sentence-splitting-numerals","title":"2) Sentence splitting + numerals","text":"<pre><code>from tamil_utils import sents, to_arabic_numerals, to_tamil_numerals\n\nprint(sents(\"\u0b87\u0ba4\u0bc1 \u0b92\u0ba9\u0bcd\u0bb1\u0bc1. \u0b87\u0ba4\u0bc1 \u0b87\u0bb0\u0ba3\u0bcd\u0b9f\u0bc1? \u0b9a\u0bb0\u0bbf!\"))\nprint(to_arabic_numerals(\"\u0be8\u0be6\u0be8\u0beb\"))  # -&gt; \"2025\"\nprint(to_tamil_numerals(\"123\"))    # -&gt; \"\u0be7\u0be8\u0be9\"\n</code></pre>"},{"location":"recipes/#3-script-detection-transliteration","title":"3) Script detection + transliteration","text":"<pre><code>from tamil_utils import tokens, token_scripts, transliterate_iso15919\n\nprint(token_scripts(tokens(\"\u0b95\u0bcb\u0b9f\u0bcd123 hello\")))\n# Example output: [(\"\u0b95\u0bcb\u0b9f\u0bcd123\", \"Mixed\"), (\"hello\", \"Latin\")]\n\nprint(transliterate_iso15919(\"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd\"))  # -&gt; \"tami\u1e3b\"\nprint(transliterate_iso15919(\"\u0b86\u0ba4\u0bbf\"))   # -&gt; \"\u0101di\"\n</code></pre>"},{"location":"recipes/#4-syllables-approximate-grapheme-based","title":"4) Syllables (approximate, grapheme-based)","text":"<pre><code>from tamil_utils import syllables\n\nprint(syllables(\"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd\ud83d\ude42 test 123\"))  # Processes Tamil clusters; ignores non-Tamil\n</code></pre>"},{"location":"recipes/#5-simple-text-stats","title":"5) Simple text stats","text":"<pre><code>from tamil_utils import word_counts\n\ntext = \"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 \u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8\"\nprint(word_counts(text, rmstop=True, preset=\"ta\", n=1))\n# -&gt; [(\"\u0b9a\u0bcb\u0ba4\u0ba9\u0bc8\", 2)]\n</code></pre>"},{"location":"recipes/#notes-tips","title":"Notes &amp; Tips","text":"<ul> <li>Collation: <code>sort_tamil</code> uses a lightweight ISO-15919 key. For strict collation (ICU), keep ours as default and layer ICU in your app if needed.</li> <li>Stopwords: You can pass your own set to <code>remove_stopwords(tokens, stopwords=my_set)</code>.</li> <li>Performance: For large corpora, stream line-by-line and aggregate <code>word_counts</code> periodically.</li> </ul>"},{"location":"spacy/","title":"spaCy Tokenizer Hook (optional)","text":"<p><code>tamil-utils</code> can install a Tamil-aware spaCy tokenizer so tokenization matches <code>tamil_utils.tokens</code>. It also normalizes input to Unicode NFC.</p>"},{"location":"spacy/#quick-start","title":"Quick start","text":"<pre><code>import spacy\nfrom tamil_utils.spacy_hook import install_tamil_tokenizer\n\nnlp = spacy.blank(\"xx\")           # use spaCy's multi-language pipeline\ninstall_tamil_tokenizer(nlp)      # replaces nlp.tokenizer; normalizes to NFC\n\ndoc = nlp(\"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0b9a\u0bcb\u0ba4\u0ba9\u0bc8 2025\")\nprint([t.text for t in doc])      # ['\u0b87\u0ba4\u0bc1','\u0b92\u0bb0\u0bc1','\u0b9a\u0bcb\u0ba4\u0ba9\u0bc8','2025']\n</code></pre>"},{"location":"spacy/#install","title":"Install","text":"<pre><code>pip install \"spacy&gt;=3.6,&lt;4\"\n# or, if you've enabled extras in your pyproject:\npip install \"tamil-utils[spacy]\"\n</code></pre>"},{"location":"spacy/#notes","title":"Notes","text":"<ul> <li>Language: <code>spacy.blank(\"xx\")</code> (multi-language) is recommended.   If you already have a pipeline (e.g., <code>en_core_web_sm</code>), call <code>install_tamil_tokenizer(nlp)</code> after loading it to replace its tokenizer.</li> <li>What it changes: Only <code>nlp.tokenizer</code> is replaced. Other pipeline components (tagger, parser, etc.) are untouched.</li> <li>Normalization: Text is normalized to NFC before tokenization to ensure consistent Tamil segmentation.</li> </ul>"},{"location":"spacy/#restore-default-tokenizer-optional","title":"Restore default tokenizer (optional)","text":"<p>If you need to revert to spaCy\u2019s default tokenizer:</p> <pre><code>from spacy.tokenizer import Tokenizer\nnlp.tokenizer = Tokenizer(nlp.vocab)\n</code></pre>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#quickstart","title":"Quickstart","text":"<pre><code>pip install tamil-utils\npython -m tamil_utils.cli sents \"\u0b87\u0ba4\u0bc1 \u0b92\u0bb0\u0bc1 \u0bb5\u0bbe\u0b95\u0bcd\u0b95\u0bbf\u0baf\u0bae\u0bcd. \u0b87\u0ba4\u0bc1 \u0b87\u0bb0\u0ba3\u0bcd\u0b9f\u0bbe\u0bae\u0bcd? \u0b9a\u0bb0\u0bbf!\"\npython -m tamil_utils.cli to-iso \"\u0ba4\u0bae\u0bbf\u0bb4\u0bcd\"\npython -m tamil_utils.cli script \"\u0b87\u0ba8\u0bcd\u0ba4 text code-mixed \u0b86\u0b95 \u0b87\u0bb0\u0bc1\u0b95\u0bcd\u0b95\u0bc1\"\n</code></pre>"}]}